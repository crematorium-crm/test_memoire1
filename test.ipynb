{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1tIDDXkbAZxK_GMSd0rnrmF6Un7mFt0tt",
      "authorship_tag": "ABX9TyPFXRYvewuNEFJbdRlPwqHh",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/crematorium-crm/test_memoire1/blob/main/test.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "dxQafSqNYqSK"
      },
      "outputs": [],
      "source": [
        "import os , glob\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.applications.resnet50 import ResNet50\n",
        "from keras.models import Model\n",
        "from keras.preprocessing.image import img_to_array, load_img\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score, classification_report"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_dir='/content/drive/MyDrive/dataSet_ISIC'\n",
        "\n",
        "\n",
        "# Chemins vers les dossiers d'entraînement et de test\n",
        "train_dir = os.path.join(data_dir, 'Train')\n",
        "test_dir = os.path.join(data_dir, 'Test')"
      ],
      "metadata": {
        "id": "laQTeJf3kH4t"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(180, 180, 3))"
      ],
      "metadata": {
        "id": "hd0ZdpI6kMjt"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "train_datagen = ImageDataGenerator(rescale=1./255, validation_split=0.1)\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n"
      ],
      "metadata": {
        "id": "7EUebSRzkUUp"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=(180, 180),\n",
        "    batch_size=32,\n",
        "    class_mode='binary',\n",
        "    subset='training'\n",
        ")\n",
        "\n",
        "validation_generator = train_datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=(180, 180),\n",
        "    batch_size=32,\n",
        "    class_mode='binary',\n",
        "    subset='validation'\n",
        ")\n",
        "\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "    test_dir,\n",
        "    target_size=(180, 180),\n",
        "    batch_size=32,\n",
        "    class_mode='binary' )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "wKIU2t-GktxX",
        "outputId": "db46c82e-1328-4db3-a92b-2d00e215ad22"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1768 images belonging to 2 classes.\n",
            "Found 195 images belonging to 2 classes.\n",
            "Found 115 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#from PIL import Image\n",
        "\n",
        "#def load_data(data_dir):\n",
        " #   images = []\n",
        "  #  labels = []\n",
        "  #  for folder in os.listdir(data_dir):\n",
        "   #     label = 1 if folder == 'malin' else 0\n",
        "    #    for image_file in os.listdir(os.path.join(data_dir, folder)):\n",
        "      #      image = Image.open(os.path.join(data_dir, folder, image_file))\n",
        "       #     image = image.resize((180, 180))\n",
        "        #    image = np.array(image)\n",
        "         #   images.append(image)\n",
        "          #  labels.append(label)\n",
        "    #return np.array(images), np.array(labels)\n",
        "\n",
        "#train_images, train_labels = load_data(train_dir)\n",
        "#test_images, test_labels = load_data(test_dir)\n",
        "\n",
        "# Séparation des données d'entraînement en ensembles d'entraînement et de validation\n",
        "#train_images, val_images, train_labels, val_labels = train_test_split(train_images, train_labels, test_size=0.1, random_state=42)"
      ],
      "metadata": {
        "id": "zRLSBoT25HnE"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "x = base_model.output\n",
        "x = Conv2D(64, (3, 3), activation='relu')(x)\n",
        "x = MaxPooling2D((2, 2))(x)\n",
        "x = Flatten()(x)\n",
        "x = Dense(128, activation='relu')(x)\n",
        "x = Dropout(0.5)(x)\n",
        "predictions = Dense(1, activation='sigmoid')(x)"
      ],
      "metadata": {
        "id": "l-_4Ade5n1rz"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "model = Model(inputs=base_model.input, outputs=predictions)"
      ],
      "metadata": {
        "id": "Gj0nJLzNorYv"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "MmFBSpnIrX4B"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_datagen = ImageDataGenerator(rescale=1./255, validation_split=0.1)\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "# Chargement des données d'entraînement et de validation\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=(180, 180),\n",
        "    batch_size=32,\n",
        "    class_mode='binary',\n",
        "    subset='training'\n",
        ")\n",
        "\n",
        "val_generator = train_datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=(180, 180),\n",
        "    batch_size=32,\n",
        "    class_mode='binary',\n",
        "    subset='validation'\n",
        ")\n",
        "\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "    test_dir,\n",
        "    target_size=(180, 180),\n",
        "    batch_size=32,\n",
        "    class_mode='binary' )\n",
        "\n",
        "# Extraction des caractéristiques pour les ensembles d'entraînement et de validation\n",
        "train_features = []\n",
        "val_features = []\n",
        "\n",
        "#for images, labels in train_generator:\n",
        "#  features = model.predict(images)\n",
        " # train_features.append(features)\n",
        "\n",
        "#for images, labels in val_generator:\n",
        " # features = model.predict(images)\n",
        "  #val_features.append(features)\n",
        "\n",
        "# Concaténation des features\n",
        "#train_features = np.concatenate(train_features)\n",
        "#val_features = np.concatenate(val_features)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "tmpbnw_57gvr",
        "outputId": "a4cf9676-8a99-4827-88f8-58c28c456bcd"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1768 images belonging to 2 classes.\n",
            "Found 195 images belonging to 2 classes.\n",
            "Found 115 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "train_features = base_model.predict(train_generator, verbose=1)\n",
        "val_features = base_model.predict(val_generator, verbose=1)\n",
        "\n",
        "# Extraction des caractéristiques pour l'ensemble de test\n",
        "test_features = base_model.predict(test_generator, verbose=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "LxMy1QwWF6As",
        "outputId": "1df8e892-189f-44e7-c8d9-8a6fafa67524"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "56/56 [==============================] - 285s 5s/step\n",
            "7/7 [==============================] - 32s 4s/step\n",
            "4/4 [==============================] - 22s 5s/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(np.unique(train_labels, return_counts=True))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "id": "EF78TYFbur3s",
        "outputId": "39e562a4-97b9-4970-b777-2024f9dea730"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'train_labels' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-dc40e029aadb>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_counts\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'train_labels' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Aplatir les caractéristiques d'entraînement et de validation\n",
        "train_features_flat = train_features.reshape(train_features.shape[0], -1)\n",
        "val_features_flat = val_features.reshape(val_features.shape[0], -1)\n",
        "test_features_flat = test_features.reshape(test_features.shape[0], -1)\n",
        "\n",
        "# Récupération des labels d'entraînement, de validation et de test\n",
        "train_labels = np.array(train_generator.classes)\n",
        "val_labels = np.array(val_generator.classes)\n",
        "test_labels = np.array(test_generator.classes)\n",
        "kernerl = 'rbf'\n",
        "\n",
        "\n",
        "clf = SVC(kernel=kernerl, probability=True, verbose=0)  # Set verbose to 0 to avoid default output\n",
        "\n",
        "# Nombre d'époques\n",
        "epochs = 10\n",
        "\n",
        "# Nombre d'échantillons à utiliser pour l'entraînement à chaque itération\n",
        "batch_size = 64\n",
        "\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    print(f\"Epoch {epoch + 1}/{epochs}\")\n",
        "\n",
        "    # Mélanger les données d'entraînement\n",
        "    indices = np.random.permutation(len(train_features_flat))\n",
        "    train_features_shuffled = train_features_flat[indices]\n",
        "    train_labels_shuffled = train_labels[indices]\n",
        "\n",
        "    # Entraîner le classifieur SVM par lots avec affichage de la progression\n",
        "    for i in tqdm(range(0, len(train_features_flat), batch_size), desc=f\"Epoch {epoch + 1} - Training\"):\n",
        "        end_index = min(i + batch_size, len(train_features_flat))\n",
        "        _ = clf.fit(train_features_shuffled[i:end_index], train_labels_shuffled[i:end_index])\n",
        "\n",
        "    # Évaluation sur les données de validation\n",
        "    val_preds = clf.predict(val_features_flat)\n",
        "    val_acc = accuracy_score(val_labels, val_preds)\n",
        "    print(f\"Validation accuracy: {val_acc:.4f}\")\n",
        "\n",
        "# Évaluation sur les données de test après toutes les époques\n",
        "test_preds = clf.predict(test_features_flat)\n",
        "test_acc = accuracy_score(test_labels, test_preds)\n",
        "print(f\"Test accuracy: {test_acc:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "ja17wsK-I2U4",
        "outputId": "dd8163fe-c624-4c08-847a-5e85f8c4bb76"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1 - Training: 100%|██████████| 28/28 [00:48<00:00,  1.72s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation accuracy: 0.5077\n",
            "Epoch 2/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2 - Training: 100%|██████████| 28/28 [00:49<00:00,  1.76s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation accuracy: 0.5231\n",
            "Epoch 3/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3 - Training: 100%|██████████| 28/28 [00:49<00:00,  1.75s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation accuracy: 0.4923\n",
            "Epoch 4/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4 - Training: 100%|██████████| 28/28 [00:48<00:00,  1.72s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation accuracy: 0.5077\n",
            "Epoch 5/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5 - Training: 100%|██████████| 28/28 [00:49<00:00,  1.75s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation accuracy: 0.5077\n",
            "Epoch 6/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 6 - Training: 100%|██████████| 28/28 [00:47<00:00,  1.70s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation accuracy: 0.4923\n",
            "Epoch 7/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 7 - Training: 100%|██████████| 28/28 [00:46<00:00,  1.68s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation accuracy: 0.4923\n",
            "Epoch 8/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 8 - Training: 100%|██████████| 28/28 [00:51<00:00,  1.85s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation accuracy: 0.4923\n",
            "Epoch 9/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 9 - Training: 100%|██████████| 28/28 [00:47<00:00,  1.70s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation accuracy: 0.5077\n",
            "Epoch 10/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 10 - Training: 100%|██████████| 28/28 [00:50<00:00,  1.79s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation accuracy: 0.5077\n",
            "Test accuracy: 0.4435\n"
          ]
        }
      ]
    }
  ]
}